name: "generate_ntp_llama"
dump_dir: "./apps/main/dump"
# metric_log_dir: str OPTIONAL
ckpt_dir: "./apps/main/ntp_llama_128/checkpoints/0000015300"
#


generator:
  # main.generate.PackedCausalTransformerGeneratorArgs
  temperature: 1.0
  top_p: 0.95
  max_gen_len: 512 # Maximum generation length
  max_tokens: 512 # Maximum number of tokens that can go through the model
  dtype: bf16

single_prompts: ["The meaning of life is", "I am", "Lisa is"]

  
# harness:
#   tasks:
#     - hellaswag
#     - task: boolq
#       dataset_kwargs:
#         trust_remote_code: true


